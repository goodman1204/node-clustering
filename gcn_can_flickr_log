nohup: ignoring input
Using Flickr dataset
dataset:Flickr, node_num:7575,edge_num:479476,attribute_num:12047
imported graph edge number (without selfloop):239738.0
cluster number:9
node size:7575, feature size:12047
graph edge number after mask:239738.0
graph edge number after normalize adjacent matrix:239738.0
Traceback (most recent call last):
  File "can.py", line 289, in <module>
    training(args)
  File "can.py", line 159, in training
    loss_list,[mu_u, logvar_u, mu_a, logvar_a,z] = model.loss(features_training,adj_norm,labels = (adj_label, features_label), n_nodes = n_nodes, n_features = n_features,norm = (norm_u, norm_a), pos_weight = (pos_weight_u, pos_weight_a))
  File "/home/syang/project/github_code/node-clustering/model.py", line 716, in loss
    cost_a = norm_a * F.binary_cross_entropy_with_logits(pred_x, labels_sub_a, pos_weight = pos_weight_a)
  File "/home/syang/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py", line 2435, in binary_cross_entropy_with_logits
    return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)
RuntimeError: CUDA out of memory. Tried to allocate 350.00 MiB (GPU 0; 31.75 GiB total capacity; 3.39 GiB already allocated; 34.50 MiB free; 3.41 GiB reserved in total by PyTorch)
